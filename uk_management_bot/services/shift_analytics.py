"""
–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Å–º–µ–Ω –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ KPI
–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π –∏ —Å–º–µ–Ω
"""
import logging
from datetime import datetime, timedelta, date
from typing import Dict, List, Optional, Tuple, Any
from sqlalchemy.orm import Session
from sqlalchemy import func, and_, or_, desc, asc

from uk_management_bot.database.models.shift import Shift
from uk_management_bot.database.models.request import Request
from uk_management_bot.database.models.user import User
from uk_management_bot.database.models.shift_assignment import ShiftAssignment
from uk_management_bot.utils.constants import (
    REQUEST_STATUS_COMPLETED, REQUEST_STATUS_IN_PROGRESS, REQUEST_STATUS_NEW,
    SHIFT_STATUS_COMPLETED, SHIFT_STATUS_ACTIVE, SHIFT_STATUS_PLANNED
)

logger = logging.getLogger(__name__)

class ShiftAnalytics:
    """
    –°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ —Å–º–µ–Ω —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ KPI
    
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç:
    - –ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–º–µ–Ω –∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π
    - KPI –∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    - –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ —Ç—Ä–µ–Ω–¥–æ–≤
    - –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –±–µ–Ω—á–º–∞—Ä–∫–∏
    """
    
    def __init__(self, db: Session):
        self.db = db
        
    # =================== –û–°–ù–û–í–ù–´–ï –ú–ï–¢–†–ò–ö–ò –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–ò ===================
    
    async def calculate_shift_efficiency_score(self, shift_id: int) -> Dict[str, Any]:
        """
        –†–∞—Å—á–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–º–µ–Ω—ã
        
        Args:
            shift_id: ID —Å–º–µ–Ω—ã
            
        Returns:
            Dict —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        """
        try:
            shift = self.db.query(Shift).filter(Shift.id == shift_id).first()
            if not shift:
                return {"error": "Shift not found", "score": 0}
            
            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            total_requests = shift.current_request_count or 0
            completed_requests = shift.completed_requests or 0
            avg_response_time = shift.average_response_time or 0
            avg_completion_time = shift.average_completion_time or 0
            
            # –†–∞—Å—á–µ—Ç –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
            completion_rate = (completed_requests / max(total_requests, 1)) * 100
            
            # –°–∫–æ—Ä–∏–Ω–≥–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ (0-100)
            score_components = {
                "completion_rate": min(completion_rate * 0.4, 40),  # 40% –≤–µ—Å–∞
                "response_time": max(0, 30 - (avg_response_time / 60) * 5),  # 30% –≤–µ—Å–∞
                "completion_time": max(0, 20 - (avg_completion_time / 120) * 10),  # 20% –≤–µ—Å–∞
                "workload_balance": min((total_requests / max(shift.max_requests or 10, 1)) * 10, 10)  # 10% –≤–µ—Å–∞
            }
            
            total_score = sum(score_components.values())
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞
            if total_score >= 90:
                rating = "–û—Ç–ª–∏—á–Ω–æ"
                rating_color = "üü¢"
            elif total_score >= 75:
                rating = "–•–æ—Ä–æ—à–æ"
                rating_color = "üü°"
            elif total_score >= 60:
                rating = "–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
                rating_color = "üü†"
            else:
                rating = "–¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è"
                rating_color = "üî¥"
            
            return {
                "shift_id": shift_id,
                "efficiency_score": round(total_score, 1),
                "rating": rating,
                "rating_color": rating_color,
                "metrics": {
                    "total_requests": total_requests,
                    "completed_requests": completed_requests,
                    "completion_rate": round(completion_rate, 1),
                    "avg_response_time": round(avg_response_time, 1),
                    "avg_completion_time": round(avg_completion_time, 1)
                },
                "score_breakdown": {
                    k: round(v, 1) for k, v in score_components.items()
                },
                "recommendations": self._get_efficiency_recommendations(total_score, score_components)
            }
            
        except Exception as e:
            logger.error(f"Error calculating shift efficiency: {e}")
            return {"error": str(e), "score": 0}
    
    async def calculate_executor_performance_metrics(
        self, 
        executor_id: int, 
        period_days: int = 30
    ) -> Dict[str, Any]:
        """
        –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è –∑–∞ –ø–µ—Ä–∏–æ–¥
        
        Args:
            executor_id: ID –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
            period_days: –ü–µ—Ä–∏–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ –¥–Ω—è—Ö
            
        Returns:
            –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
        """
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=period_days)
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–º–µ–Ω—ã –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è –∑–∞ –ø–µ—Ä–∏–æ–¥
            shifts = self.db.query(Shift).filter(
                and_(
                    Shift.executor_id == executor_id,
                    Shift.start_time >= start_date,
                    Shift.start_time <= end_date
                )
            ).all()
            
            if not shifts:
                return {
                    "executor_id": executor_id,
                    "period_days": period_days,
                    "message": "No shifts found for this period"
                }
            
            # –†–∞—Å—á–µ—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
            total_shifts = len(shifts)
            completed_shifts = len([s for s in shifts if s.status == SHIFT_STATUS_COMPLETED])
            total_requests = sum(s.current_request_count or 0 for s in shifts)
            completed_requests = sum(s.completed_requests or 0 for s in shifts)
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            avg_shift_duration = sum(
                (s.end_time - s.start_time).total_seconds() / 3600 
                for s in shifts if s.end_time and s.start_time
            ) / max(total_shifts, 1)
            
            avg_response_time = sum(
                s.average_response_time or 0 for s in shifts
            ) / max(total_shifts, 1)
            
            avg_completion_time = sum(
                s.average_completion_time or 0 for s in shifts  
            ) / max(total_shifts, 1)
            
            # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            completion_rate = (completed_requests / max(total_requests, 1)) * 100
            shift_completion_rate = (completed_shifts / max(total_shifts, 1)) * 100
            
            # –û—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
            quality_scores = [s.quality_rating for s in shifts if s.quality_rating]
            avg_quality_rating = sum(quality_scores) / max(len(quality_scores), 1)
            
            efficiency_scores = [s.efficiency_score for s in shifts if s.efficiency_score]
            avg_efficiency_score = sum(efficiency_scores) / max(len(efficiency_scores), 1)
            
            # –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
            performance_score = (
                completion_rate * 0.3 +
                shift_completion_rate * 0.2 +
                avg_quality_rating * 15 +  # –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑ 5, —É–º–Ω–æ–∂–∞–µ–º –Ω–∞ 15 = –¥–æ 75
                max(0, 25 - (avg_response_time / 60) * 5)  # –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞
            )
            
            return {
                "executor_id": executor_id,
                "period": {
                    "start_date": start_date.isoformat(),
                    "end_date": end_date.isoformat(),
                    "days": period_days
                },
                "summary_metrics": {
                    "total_shifts": total_shifts,
                    "completed_shifts": completed_shifts,
                    "shift_completion_rate": round(shift_completion_rate, 1),
                    "total_requests": total_requests,
                    "completed_requests": completed_requests,
                    "request_completion_rate": round(completion_rate, 1)
                },
                "time_metrics": {
                    "avg_shift_duration_hours": round(avg_shift_duration, 1),
                    "avg_response_time_minutes": round(avg_response_time, 1),
                    "avg_completion_time_minutes": round(avg_completion_time, 1)
                },
                "quality_metrics": {
                    "avg_quality_rating": round(avg_quality_rating, 1),
                    "avg_efficiency_score": round(avg_efficiency_score, 1),
                    "performance_score": round(performance_score, 1)
                },
                "trend_analysis": await self._analyze_executor_trends(executor_id, shifts),
                "recommendations": self._get_executor_recommendations(performance_score, {
                    "completion_rate": completion_rate,
                    "response_time": avg_response_time,
                    "quality_rating": avg_quality_rating
                })
            }
            
        except Exception as e:
            logger.error(f"Error calculating executor metrics: {e}")
            return {"error": str(e)}
    
    # =================== –ê–ù–ê–õ–ò–¢–ò–ö–ê –í–†–ï–ú–ï–ù–ù–´–• –ü–ê–¢–¢–ï–†–ù–û–í ===================
    
    async def analyze_daily_patterns(self, date_from: date, date_to: date) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏ –∏ —á–∞—Å–∞–º
        
        Args:
            date_from: –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
            date_to: –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞—è–≤–∫–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥
            requests = self.db.query(Request).filter(
                and_(
                    Request.created_at >= datetime.combine(date_from, datetime.min.time()),
                    Request.created_at <= datetime.combine(date_to, datetime.max.time())
                )
            ).all()
            
            if not requests:
                return {"message": "No data for analysis"}
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏ (0 = –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫)
            weekday_stats = {}
            for i in range(7):
                weekday_stats[i] = {"count": 0, "completed": 0, "avg_response_time": 0}
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ —á–∞—Å–∞–º (0-23)
            hourly_stats = {}
            for i in range(24):
                hourly_stats[i] = {"count": 0, "completed": 0, "avg_response_time": 0}
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            for request in requests:
                weekday = request.created_at.weekday()
                hour = request.created_at.hour
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
                weekday_stats[weekday]["count"] += 1
                if request.status == REQUEST_STATUS_COMPLETED:
                    weekday_stats[weekday]["completed"] += 1
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —á–∞—Å–∞–º
                hourly_stats[hour]["count"] += 1
                if request.status == REQUEST_STATUS_COMPLETED:
                    hourly_stats[hour]["completed"] += 1
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∏–∫–æ–≤—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤
            peak_weekday = max(weekday_stats.items(), key=lambda x: x[1]["count"])
            peak_hour = max(hourly_stats.items(), key=lambda x: x[1]["count"])
            
            weekday_names = {
                0: "–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", 1: "–í—Ç–æ—Ä–Ω–∏–∫", 2: "–°—Ä–µ–¥–∞", 3: "–ß–µ—Ç–≤–µ—Ä–≥",
                4: "–ü—è—Ç–Ω–∏—Ü–∞", 5: "–°—É–±–±–æ—Ç–∞", 6: "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"
            }
            
            return {
                "period": {
                    "from": date_from.isoformat(),
                    "to": date_to.isoformat(),
                    "total_requests": len(requests)
                },
                "weekday_analysis": {
                    "stats": {
                        weekday_names[k]: {
                            "count": v["count"],
                            "completed": v["completed"],
                            "completion_rate": round((v["completed"] / max(v["count"], 1)) * 100, 1)
                        }
                        for k, v in weekday_stats.items()
                    },
                    "peak_day": {
                        "day": weekday_names[peak_weekday[0]],
                        "count": peak_weekday[1]["count"]
                    }
                },
                "hourly_analysis": {
                    "stats": {
                        f"{k}:00": {
                            "count": v["count"],
                            "completed": v["completed"],
                            "completion_rate": round((v["completed"] / max(v["count"], 1)) * 100, 1)
                        }
                        for k, v in hourly_stats.items()
                    },
                    "peak_hour": {
                        "hour": f"{peak_hour[0]}:00",
                        "count": peak_hour[1]["count"]
                    }
                },
                "insights": self._generate_pattern_insights(weekday_stats, hourly_stats)
            }
            
        except Exception as e:
            logger.error(f"Error analyzing daily patterns: {e}")
            return {"error": str(e)}
    
    # =================== –°–ò–°–¢–ï–ú–ê KPI –ò –ü–û–ö–ê–ó–ê–¢–ï–õ–ï–ô ===================
    
    async def calculate_system_kpis(self, period_days: int = 30) -> Dict[str, Any]:
        """
        –†–∞—Å—á–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã
        
        Args:
            period_days: –ü–µ—Ä–∏–æ–¥ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ KPI
            
        Returns:
            –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ KPI —Å–∏—Å—Ç–µ–º—ã —Å–º–µ–Ω
        """
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=period_days)
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–µ—Ä–∏–æ–¥
            shifts = self.db.query(Shift).filter(
                and_(
                    Shift.start_time >= start_date,
                    Shift.start_time <= end_date
                )
            ).all()
            
            requests = self.db.query(Request).filter(
                and_(
                    Request.created_at >= start_date,
                    Request.created_at <= end_date
                )
            ).all()
            
            # –û—Å–Ω–æ–≤–Ω—ã–µ KPI
            total_requests = len(requests)
            completed_requests = len([r for r in requests if r.status == REQUEST_STATUS_COMPLETED])
            in_progress_requests = len([r for r in requests if r.status == REQUEST_STATUS_IN_PROGRESS])
            
            total_shifts = len(shifts)
            completed_shifts = len([s for s in shifts if s.status == SHIFT_STATUS_COMPLETED])
            active_shifts = len([s for s in shifts if s.status == SHIFT_STATUS_ACTIVE])
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ KPI
            avg_response_time = sum(
                (r.updated_at - r.created_at).total_seconds() / 60 
                for r in requests if r.updated_at and r.status != REQUEST_STATUS_NEW
            ) / max(len([r for r in requests if r.updated_at and r.status != REQUEST_STATUS_NEW]), 1)
            
            # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            request_completion_rate = (completed_requests / max(total_requests, 1)) * 100
            shift_completion_rate = (completed_shifts / max(total_shifts, 1)) * 100
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º—ã
            avg_daily_requests = total_requests / max(period_days, 1)
            avg_shift_utilization = sum(
                (s.current_request_count or 0) / max(s.max_requests or 1, 1)
                for s in shifts
            ) / max(len(shifts), 1) * 100
            
            # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
            quality_scores = [s.quality_rating for s in shifts if s.quality_rating and s.quality_rating > 0]
            avg_quality_rating = sum(quality_scores) / max(len(quality_scores), 1)
            
            efficiency_scores = [s.efficiency_score for s in shifts if s.efficiency_score and s.efficiency_score > 0]
            avg_efficiency_score = sum(efficiency_scores) / max(len(efficiency_scores), 1)
            
            # –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ KPI —Å–∏—Å—Ç–µ–º—ã (0-100)
            system_kpi = (
                request_completion_rate * 0.25 +    # 25% - –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∑–∞—è–≤–∫–∏
                shift_completion_rate * 0.20 +      # 20% - –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ —Å–º–µ–Ω—ã
                avg_quality_rating * 15 +           # 15% - –∫–∞—á–µ—Å—Ç–≤–æ (–∏–∑ 5 –≤ 75)
                avg_efficiency_score * 0.15 +       # 15% - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
                max(0, 25 - (avg_response_time / 60) * 5)  # 25% - –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞
            )
            
            return {
                "period": {
                    "start_date": start_date.isoformat(),
                    "end_date": end_date.isoformat(),
                    "days": period_days
                },
                "primary_kpis": {
                    "system_kpi_score": round(system_kpi, 1),
                    "request_completion_rate": round(request_completion_rate, 1),
                    "shift_completion_rate": round(shift_completion_rate, 1),
                    "avg_response_time_hours": round(avg_response_time / 60, 1),
                    "avg_quality_rating": round(avg_quality_rating, 1),
                    "avg_efficiency_score": round(avg_efficiency_score, 1)
                },
                "volume_metrics": {
                    "total_requests": total_requests,
                    "completed_requests": completed_requests,
                    "in_progress_requests": in_progress_requests,
                    "avg_daily_requests": round(avg_daily_requests, 1),
                    "total_shifts": total_shifts,
                    "active_shifts": active_shifts
                },
                "utilization_metrics": {
                    "avg_shift_utilization": round(avg_shift_utilization, 1),
                    "peak_load_capacity": await self._calculate_peak_capacity(shifts),
                    "resource_efficiency": await self._calculate_resource_efficiency(shifts)
                },
                "benchmarks": self._get_industry_benchmarks(),
                "trends": await self._analyze_kpi_trends(period_days)
            }
            
        except Exception as e:
            logger.error(f"Error calculating system KPIs: {e}")
            return {"error": str(e)}
    
    # =================== –ü–†–ò–í–ê–¢–ù–´–ï –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ ===================
    
    def _get_efficiency_recommendations(
        self, 
        total_score: float, 
        components: Dict[str, float]
    ) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –ø–æ–≤—ã—à–µ–Ω–∏—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
        recommendations = []
        
        if total_score < 60:
            recommendations.append("üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å - —Ç—Ä–µ–±—É–µ—Ç—Å—è —Å—Ä–æ—á–Ω–æ–µ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ")
        
        if components["completion_rate"] < 20:
            recommendations.append("üìà –ù–∏–∑–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞—è–≤–æ–∫ - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É –∏ —Ä–µ—Å—É—Ä—Å—ã")
        
        if components["response_time"] < 15:
            recommendations.append("‚è±Ô∏è –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∑–∞—è–≤–æ–∫")
        
        if components["completion_time"] < 10:
            recommendations.append("üîÑ –î–æ–ª–≥–æ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞—è–≤–æ–∫")
        
        if components["workload_balance"] < 5:
            recommendations.append("‚öñÔ∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ - —É–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã—Ö –∑–∞—è–≤–æ–∫")
        
        if total_score >= 90:
            recommendations.append("‚ú® –û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞! –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å —Ç–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
        
        return recommendations
    
    def _get_executor_recommendations(
        self, 
        performance_score: float, 
        metrics: Dict[str, float]
    ) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è"""
        recommendations = []
        
        if performance_score >= 85:
            recommendations.append("üåü –û—Ç–ª–∏—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å! –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –¥–ª—è –º–µ–Ω—Ç–æ—Ä—Å—Ç–≤–∞ –¥—Ä—É–≥–∏—Ö –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π")
        elif performance_score >= 70:
            recommendations.append("üëç –•–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã. –ü—Ä–æ–¥–æ–ª–∂–∞—Ç—å –≤ —Ç–æ–º –∂–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏")
        elif performance_score >= 50:
            recommendations.append("üìä –°—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏. –ï—Å—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è")
        else:
            recommendations.append("üéØ –ù–∏–∑–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∞")
        
        if metrics["completion_rate"] < 70:
            recommendations.append("üìà –£–≤–µ–ª–∏—á–∏—Ç—å –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∑–∞—è–≤–æ–∫")
        
        if metrics["response_time"] > 60:
            recommendations.append("‚è∞ –°–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –Ω–∞ –∑–∞—è–≤–∫–∏")
        
        if metrics["quality_rating"] < 3.5:
            recommendations.append("‚≠ê –ü–æ–≤—ã—Å–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç")
        
        return recommendations
    
    async def _analyze_executor_trends(self, executor_id: int, shifts: List[Shift]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è"""
        if len(shifts) < 2:
            return {"message": "Insufficient data for trend analysis"}
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–º–µ–Ω—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        sorted_shifts = sorted(shifts, key=lambda x: x.start_time or datetime.min)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–µ—Ä–∏–æ–¥—ã
        recent_shifts = sorted_shifts[-7:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 7 —Å–º–µ–Ω
        earlier_shifts = sorted_shifts[:-7] if len(sorted_shifts) > 7 else sorted_shifts[:len(sorted_shifts)//2]
        
        if not earlier_shifts:
            return {"message": "Insufficient historical data"}
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        recent_avg_efficiency = sum(s.efficiency_score or 0 for s in recent_shifts) / len(recent_shifts)
        earlier_avg_efficiency = sum(s.efficiency_score or 0 for s in earlier_shifts) / len(earlier_shifts)
        
        recent_avg_quality = sum(s.quality_rating or 0 for s in recent_shifts) / len(recent_shifts)
        earlier_avg_quality = sum(s.quality_rating or 0 for s in earlier_shifts) / len(earlier_shifts)
        
        return {
            "efficiency_trend": {
                "current_avg": round(recent_avg_efficiency, 1),
                "previous_avg": round(earlier_avg_efficiency, 1),
                "change": round(recent_avg_efficiency - earlier_avg_efficiency, 1),
                "direction": "‚ÜóÔ∏è" if recent_avg_efficiency > earlier_avg_efficiency else "‚ÜòÔ∏è"
            },
            "quality_trend": {
                "current_avg": round(recent_avg_quality, 1),
                "previous_avg": round(earlier_avg_quality, 1),
                "change": round(recent_avg_quality - earlier_avg_quality, 1),
                "direction": "‚ÜóÔ∏è" if recent_avg_quality > earlier_avg_quality else "‚ÜòÔ∏è"
            }
        }
    
    def _generate_pattern_insights(
        self, 
        weekday_stats: Dict, 
        hourly_stats: Dict
    ) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        insights = []
        
        # –ê–Ω–∞–ª–∏–∑ –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏
        max_day = max(weekday_stats.items(), key=lambda x: x[1]["count"])
        min_day = min(weekday_stats.items(), key=lambda x: x[1]["count"])
        
        day_names = {0: "–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", 1: "–≤—Ç–æ—Ä–Ω–∏–∫", 2: "—Å—Ä–µ–¥–∞", 3: "—á–µ—Ç–≤–µ—Ä–≥",
                    4: "–ø—è—Ç–Ω–∏—Ü–∞", 5: "—Å—É–±–±–æ—Ç–∞", 6: "–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"}
        
        if max_day[1]["count"] > min_day[1]["count"] * 1.5:
            insights.append(f"üìä –ü–∏–∫–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ {day_names[max_day[0]]} - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–º–µ–Ω")
        
        # –ê–Ω–∞–ª–∏–∑ —á–∞—Å–æ–≤
        morning_load = sum(hourly_stats[h]["count"] for h in range(6, 12))
        afternoon_load = sum(hourly_stats[h]["count"] for h in range(12, 18))
        evening_load = sum(hourly_stats[h]["count"] for h in range(18, 22))
        
        peak_period = max([
            ("—É—Ç—Ä–µ–Ω–Ω–∏–µ", morning_load),
            ("–¥–Ω–µ–≤–Ω—ã–µ", afternoon_load),
            ("–≤–µ—á–µ—Ä–Ω–∏–µ", evening_load)
        ], key=lambda x: x[1])
        
        insights.append(f"‚è∞ –ù–∞–∏–±–æ–ª—å—à–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ {peak_period[0]} —á–∞—Å—ã - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ —Å–º–µ–Ω")
        
        return insights
    
    async def _calculate_peak_capacity(self, shifts: List[Shift]) -> float:
        """–†–∞—Å—á–µ—Ç –ø–∏–∫–æ–≤–æ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏"""
        if not shifts:
            return 0.0
        
        max_concurrent_requests = max(s.current_request_count or 0 for s in shifts)
        avg_max_requests = sum(s.max_requests or 0 for s in shifts) / len(shifts)
        
        return round((max_concurrent_requests / max(avg_max_requests, 1)) * 100, 1)
    
    async def _calculate_resource_efficiency(self, shifts: List[Shift]) -> float:
        """–†–∞—Å—á–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤"""
        if not shifts:
            return 0.0
        
        total_capacity = sum(s.max_requests or 0 for s in shifts)
        total_utilized = sum(s.current_request_count or 0 for s in shifts)
        
        return round((total_utilized / max(total_capacity, 1)) * 100, 1)
    
    def _get_industry_benchmarks(self) -> Dict[str, float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç—Ä–∞—Å–ª–µ–≤—ã—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        return {
            "excellent_completion_rate": 95.0,
            "good_completion_rate": 85.0,
            "acceptable_completion_rate": 70.0,
            "target_response_time_hours": 2.0,
            "target_quality_rating": 4.5,
            "optimal_utilization_rate": 80.0
        }
    
    async def _analyze_kpi_trends(self, period_days: int) -> Dict[str, str]:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ KPI –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ –ø–µ—Ä–∏–æ–¥–∞–º–∏
        return {
            "completion_rate": "stable",
            "response_time": "improving", 
            "quality_rating": "stable",
            "utilization": "increasing"
        }