"""
–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å–º–µ–Ω
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç actionable —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
"""
import logging
from datetime import datetime, timedelta, date
from typing import Dict, List, Optional, Any, Tuple
from sqlalchemy.orm import Session
from sqlalchemy import func, and_, or_, desc, asc
from dataclasses import dataclass
from enum import Enum

from uk_management_bot.database.models.shift import Shift
from uk_management_bot.database.models.request import Request
from uk_management_bot.database.models.user import User
from uk_management_bot.database.models.shift_assignment import ShiftAssignment
from uk_management_bot.services.shift_analytics import ShiftAnalytics
from uk_management_bot.utils.constants import (
    REQUEST_STATUS_COMPLETED, REQUEST_STATUS_IN_PROGRESS, REQUEST_STATUS_NEW,
    SHIFT_STATUS_COMPLETED, SHIFT_STATUS_ACTIVE, SHIFT_STATUS_PLANNED,
    SPECIALIZATIONS
)

logger = logging.getLogger(__name__)

class RecommendationType(Enum):
    """–¢–∏–ø—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    SHIFT_OPTIMIZATION = "shift_optimization"
    WORKLOAD_BALANCE = "workload_balance"
    RESOURCE_ALLOCATION = "resource_allocation"
    PERFORMANCE_IMPROVEMENT = "performance_improvement"
    BOTTLENECK_RESOLUTION = "bottleneck_resolution"
    CAPACITY_PLANNING = "capacity_planning"
    QUALITY_ENHANCEMENT = "quality_enhancement"

class RecommendationPriority(Enum):
    """–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    CRITICAL = "critical"      # –¢—Ä–µ–±—É–µ—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è
    HIGH = "high"             # –í–∞–∂–Ω–æ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    MEDIUM = "medium"         # –ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é
    LOW = "low"              # –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

@dataclass
class Recommendation:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
    id: str
    type: RecommendationType
    priority: RecommendationPriority
    title: str
    description: str
    impact: str
    effort: str
    timeline: str
    actions: List[str]
    metrics: Dict[str, Any]
    confidence: float  # 0-100%

class RecommendationEngine:
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —Å–º–µ–Ω
    
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –≤—ã—è–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è
    –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –∏ ML-–∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
    """
    
    def __init__(self, db: Session):
        self.db = db
        self.analytics = ShiftAnalytics(db)
        
    # =================== –û–°–ù–û–í–ù–´–ï –ú–ï–¢–û–î–´ –ì–ï–ù–ï–†–ê–¶–ò–ò –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô ===================
    
    async def generate_comprehensive_recommendations(
        self, 
        period_days: int = 30
    ) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —Å–∏—Å—Ç–µ–º—ã
        
        Args:
            period_days: Period –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        """
        try:
            recommendations = []
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã —Å–∏—Å—Ç–µ–º—ã
            shift_recs = await self._analyze_shift_optimization(period_days)
            workload_recs = await self._analyze_workload_balance(period_days) 
            performance_recs = await self._analyze_performance_issues(period_days)
            capacity_recs = await self._analyze_capacity_planning(period_days)
            quality_recs = await self._analyze_quality_enhancement(period_days)
            bottleneck_recs = await self._identify_bottlenecks(period_days)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            all_recommendations = (
                shift_recs + workload_recs + performance_recs + 
                capacity_recs + quality_recs + bottleneck_recs
            )
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            sorted_recommendations = sorted(
                all_recommendations,
                key=lambda x: (
                    self._get_priority_weight(x.priority),
                    x.confidence
                ),
                reverse=True
            )
            
            return {
                "generated_at": datetime.now().isoformat(),
                "period_analyzed_days": period_days,
                "total_recommendations": len(sorted_recommendations),
                "recommendations": [self._recommendation_to_dict(r) for r in sorted_recommendations],
                "summary": {
                    "critical": len([r for r in sorted_recommendations if r.priority == RecommendationPriority.CRITICAL]),
                    "high": len([r for r in sorted_recommendations if r.priority == RecommendationPriority.HIGH]),
                    "medium": len([r for r in sorted_recommendations if r.priority == RecommendationPriority.MEDIUM]),
                    "low": len([r for r in sorted_recommendations if r.priority == RecommendationPriority.LOW])
                },
                "quick_wins": [
                    self._recommendation_to_dict(r) for r in sorted_recommendations 
                    if r.effort == "–ù–∏–∑–∫–∞—è" and r.priority in [RecommendationPriority.HIGH, RecommendationPriority.CRITICAL]
                ][:3]
            }
            
        except Exception as e:
            logger.error(f"Error generating recommendations: {e}")
            return {"error": str(e)}
    
    async def suggest_shift_adjustments(
        self, 
        target_date: date,
        specialization: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–µ —Å–º–µ–Ω –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É
        
        Args:
            target_date: –î–∞—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            specialization: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —Ñ–æ–∫—É—Å–∞ –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∏–∑–º–µ–Ω–µ–Ω–∏—é —Å–º–µ–Ω
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–º–µ–Ω—ã –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—É—é –¥–∞—Ç—É
            date_start = datetime.combine(target_date, datetime.min.time())
            date_end = datetime.combine(target_date, datetime.max.time())
            
            shifts = self.db.query(Shift).filter(
                and_(
                    Shift.start_time >= date_start,
                    Shift.start_time <= date_end
                )
            ).all()
            
            if specialization:
                shifts = [s for s in shifts if specialization in (s.specialization_focus or [])]
            
            recommendations = []
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è –≤—Ä–µ–º–µ–Ω–∏
            coverage_analysis = await self._analyze_time_coverage(shifts, target_date)
            if coverage_analysis["gaps"]:
                recommendations.append(
                    f"üïê –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–µ–ª—ã –≤ –ø–æ–∫—Ä—ã—Ç–∏–∏: {', '.join(coverage_analysis['gaps'])}"
                )
            
            # –ê–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏
            for shift in shifts:
                utilization = (shift.current_request_count or 0) / max(shift.max_requests or 1, 1)
                
                if utilization > 0.9:  # –ü–µ—Ä–µ–≥—Ä—É–∑–∫–∞
                    recommendations.append(
                        f"‚ö†Ô∏è –°–º–µ–Ω–∞ {shift.id} –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞ ({utilization*100:.1f}%) - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ä–∞–∑–≥—Ä—É–∑–∫–∞"
                    )
                elif utilization < 0.3:  # –ù–µ–¥–æ–≥—Ä—É–∑–∫–∞
                    recommendations.append(
                        f"üìä –°–º–µ–Ω–∞ {shift.id} –Ω–µ–¥–æ–≥—Ä—É–∂–µ–Ω–∞ ({utilization*100:.1f}%) - –º–æ–∂–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å"
                    )
            
            # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ –¥–µ–Ω—å
            historical_data = await self._get_historical_data_for_date(target_date)
            predicted_load = await self._predict_daily_load(target_date, historical_data)
            
            if predicted_load > sum(s.max_requests or 0 for s in shifts):
                recommendations.append(
                    f"üìà –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ ({predicted_load}) –ø—Ä–µ–≤—ã—à–∞–µ—Ç —Ç–µ–∫—É—â—É—é –ø—Ä–æ–ø—É—Å–∫–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å - –¥–æ–±–∞–≤–∏—Ç—å —Å–º–µ–Ω—ã"
                )
            
            return {
                "date": target_date.isoformat(),
                "specialization": specialization,
                "current_shifts": len(shifts),
                "total_capacity": sum(s.max_requests or 0 for s in shifts),
                "predicted_load": predicted_load,
                "coverage_analysis": coverage_analysis,
                "recommendations": recommendations,
                "suggested_actions": self._generate_action_plan(recommendations)
            }
            
        except Exception as e:
            logger.error(f"Error suggesting shift adjustments: {e}")
            return {"error": str(e)}
    
    async def identify_performance_bottlenecks(self, period_days: int = 7) -> Dict[str, Any]:
        """
        –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É–∑–∫–∏—Ö –º–µ—Å—Ç –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        
        Args:
            period_days: –ü–µ—Ä–∏–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É–∑–∫–∏—Ö –º–µ—Å—Ç –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        """
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=period_days)
            
            bottlenecks = []
            
            # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫–ª–∏–∫–∞
            slow_response_shifts = self.db.query(Shift).filter(
                and_(
                    Shift.start_time >= start_date,
                    Shift.average_response_time > 120  # –ë–æ–ª—å—à–µ 2 —á–∞—Å–æ–≤
                )
            ).all()
            
            if slow_response_shifts:
                bottlenecks.append({
                    "type": "slow_response",
                    "title": "–ú–µ–¥–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞",
                    "count": len(slow_response_shifts),
                    "impact": "–°–Ω–∏–∂–µ–Ω–∏–µ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤",
                    "shifts": [s.id for s in slow_response_shifts],
                    "recommendation": "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –∑–∞—è–≤–æ–∫"
                })
            
            # –ê–Ω–∞–ª–∏–∑ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∑–∞—è–≤–æ–∫
            pending_requests = self.db.query(Request).filter(
                and_(
                    Request.created_at >= start_date,
                    Request.status == REQUEST_STATUS_NEW
                )
            ).count()
            
            if pending_requests > 50:  # –ú–Ω–æ–≥–æ –æ–∂–∏–¥–∞—é—â–∏—Ö –∑–∞—è–≤–æ–∫
                bottlenecks.append({
                    "type": "pending_backlog",
                    "title": "–ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞—è–≤–æ–∫",
                    "count": pending_requests,
                    "impact": "–£—Ö—É–¥—à–µ–Ω–∏–µ SLA –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è",
                    "recommendation": "–£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–º–µ–Ω –∏–ª–∏ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π"
                })
            
            # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π
            overloaded_executors = await self._find_overloaded_executors(start_date, end_date)
            if overloaded_executors:
                bottlenecks.append({
                    "type": "executor_overload",
                    "title": "–ü–µ—Ä–µ–≥—Ä—É–∑–∫–∞ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π",
                    "count": len(overloaded_executors),
                    "impact": "–°–Ω–∏–∂–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞–±–æ—Ç—ã –∏ –≤—ã–≥–æ—Ä–∞–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–ª–∞",
                    "executors": overloaded_executors,
                    "recommendation": "–ü–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É –º–µ–∂–¥—É –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º–∏"
                })
            
            # –ê–Ω–∞–ª–∏–∑ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–π
            specialization_efficiency = await self._analyze_specialization_efficiency(start_date, end_date)
            inefficient_specs = [
                spec for spec, efficiency in specialization_efficiency.items()
                if efficiency < 0.6
            ]
            
            if inefficient_specs:
                bottlenecks.append({
                    "type": "specialization_inefficiency",
                    "title": "–ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏",
                    "specializations": inefficient_specs,
                    "impact": "–ù–∏–∑–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞—è–≤–æ–∫",
                    "recommendation": "–û–±—É—á–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤ –∏–ª–∏ –ø–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞—è–≤–æ–∫"
                })
            
            return {
                "period": {
                    "start": start_date.isoformat(),
                    "end": end_date.isoformat(),
                    "days": period_days
                },
                "bottlenecks_found": len(bottlenecks),
                "bottlenecks": bottlenecks,
                "priority_actions": self._prioritize_bottleneck_actions(bottlenecks),
                "estimated_improvement": self._estimate_bottleneck_impact(bottlenecks)
            }
            
        except Exception as e:
            logger.error(f"Error identifying bottlenecks: {e}")
            return {"error": str(e)}
    
    async def recommend_capacity_adjustments(
        self, 
        forecast_days: int = 14
    ) -> Dict[str, Any]:
        """
        –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–µ –º–æ—â–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
        
        Args:
            forecast_days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏–∑–º–µ–Ω–µ–Ω–∏—é capacity
        """
        try:
            current_date = datetime.now().date()
            recommendations = []
            
            for days_ahead in range(1, forecast_days + 1):
                target_date = current_date + timedelta(days=days_ahead)
                
                # –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞–≥—Ä—É–∑–∫–∏
                historical_data = await self._get_historical_data_for_date(target_date)
                predicted_requests = await self._predict_daily_load(target_date, historical_data)
                
                # –¢–µ–∫—É—â–∏–µ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–º–µ–Ω—ã
                planned_shifts = self.db.query(Shift).filter(
                    and_(
                        func.date(Shift.start_time) == target_date,
                        Shift.status == SHIFT_STATUS_PLANNED
                    )
                ).all()
                
                current_capacity = sum(s.max_requests or 0 for s in planned_shifts)
                utilization = (predicted_requests / max(current_capacity, 1)) * 100
                
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                if utilization > 90:  # –ü–µ—Ä–µ–≥—Ä—É–∑–∫–∞
                    additional_capacity = int((predicted_requests - current_capacity * 0.8) / 8)  # 8 –∑–∞—è–≤–æ–∫ –Ω–∞ —Å–º–µ–Ω—É
                    recommendations.append({
                        "date": target_date.isoformat(),
                        "type": "increase_capacity",
                        "current_capacity": current_capacity,
                        "predicted_load": predicted_requests,
                        "utilization": round(utilization, 1),
                        "recommendation": f"–î–æ–±–∞–≤–∏—Ç—å {additional_capacity} —Å–º–µ–Ω",
                        "priority": "high" if utilization > 110 else "medium"
                    })
                elif utilization < 50:  # –ù–µ–¥–æ–≥—Ä—É–∑–∫–∞
                    excess_capacity = int((current_capacity * 0.5 - predicted_requests) / 8)
                    recommendations.append({
                        "date": target_date.isoformat(),
                        "type": "reduce_capacity", 
                        "current_capacity": current_capacity,
                        "predicted_load": predicted_requests,
                        "utilization": round(utilization, 1),
                        "recommendation": f"–ú–æ–∂–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –Ω–∞ {excess_capacity} —Å–º–µ–Ω",
                        "priority": "low"
                    })
            
            return {
                "forecast_period_days": forecast_days,
                "total_recommendations": len(recommendations),
                "recommendations": recommendations,
                "summary": {
                    "capacity_increases": len([r for r in recommendations if r["type"] == "increase_capacity"]),
                    "capacity_reductions": len([r for r in recommendations if r["type"] == "reduce_capacity"]),
                    "high_priority_days": len([r for r in recommendations if r["priority"] == "high"])
                }
            }
            
        except Exception as e:
            logger.error(f"Error recommending capacity adjustments: {e}")
            return {"error": str(e)}
    
    # =================== –ü–†–ò–í–ê–¢–ù–´–ï –ú–ï–¢–û–î–´ –ê–ù–ê–õ–ò–ó–ê ===================
    
    async def _analyze_shift_optimization(self, period_days: int) -> List[Recommendation]:
        """–ê–Ω–∞–ª–∏–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–º–µ–Ω"""
        recommendations = []
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)
        
        # –ù–∞–π–¥–µ–º –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Å–º–µ–Ω—ã
        inefficient_shifts = self.db.query(Shift).filter(
            and_(
                Shift.start_time >= start_date,
                Shift.efficiency_score < 60
            )
        ).all()
        
        if len(inefficient_shifts) > 5:
            recommendations.append(Recommendation(
                id="shift_opt_001",
                type=RecommendationType.SHIFT_OPTIMIZATION,
                priority=RecommendationPriority.HIGH,
                title="–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —Å–º–µ–Ω",
                description=f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(inefficient_shifts)} —Å–º–µ–Ω —Å –Ω–∏–∑–∫–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é (<60%)",
                impact="–ü–æ–≤—ã—à–µ–Ω–∏–µ –æ–±—â–µ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞ 15-25%",
                effort="–°—Ä–µ–¥–Ω—è—è",
                timeline="1-2 –Ω–µ–¥–µ–ª–∏",
                actions=[
                    "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏—á–∏–Ω—ã –Ω–∏–∑–∫–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏",
                    "–ü–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏",
                    "–ü—Ä–æ–≤–µ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π",
                    "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏ —Å–º–µ–Ω"
                ],
                metrics={"inefficient_shifts": len(inefficient_shifts)},
                confidence=85.0
            ))
        
        return recommendations
    
    async def _analyze_workload_balance(self, period_days: int) -> List[Recommendation]:
        """–ê–Ω–∞–ª–∏–∑ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏"""
        recommendations = []
        
        # –ù–∞–π–¥–µ–º –¥–∏—Å–±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º–∏
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)
        
        executor_loads = {}
        shifts = self.db.query(Shift).filter(
            Shift.start_time >= start_date
        ).all()
        
        for shift in shifts:
            executor_id = shift.executor_id
            if executor_id:
                if executor_id not in executor_loads:
                    executor_loads[executor_id] = 0
                executor_loads[executor_id] += shift.current_request_count or 0
        
        if len(executor_loads) > 1:
            loads = list(executor_loads.values())
            avg_load = sum(loads) / len(loads)
            max_load = max(loads)
            min_load = min(loads)
            
            imbalance_ratio = (max_load - min_load) / max(avg_load, 1)
            
            if imbalance_ratio > 0.5:  # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å
                recommendations.append(Recommendation(
                    id="balance_001",
                    type=RecommendationType.WORKLOAD_BALANCE,
                    priority=RecommendationPriority.MEDIUM,
                    title="–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –Ω–∞–≥—Ä—É–∑–∫–∏ –º–µ–∂–¥—É –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º–∏",
                    description=f"–î–∏—Å–±–∞–ª–∞–Ω—Å –Ω–∞–≥—Ä—É–∑–∫–∏: {imbalance_ratio*100:.1f}%",
                    impact="–£–ª—É—á—à–µ–Ω–∏–µ –º–æ—Ä–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏",
                    effort="–ù–∏–∑–∫–∞—è",
                    timeline="1 –Ω–µ–¥–µ–ª—è",
                    actions=[
                        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞—è–≤–æ–∫",
                        "–í–Ω–µ–¥—Ä–∏—Ç—å –±–æ–ª–µ–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ",
                        "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É"
                    ],
                    metrics={"imbalance_ratio": round(imbalance_ratio * 100, 1)},
                    confidence=90.0
                ))
        
        return recommendations
    
    async def _analyze_performance_issues(self, period_days: int) -> List[Recommendation]:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        recommendations = []
        
        # –ü–æ–∏—Å–∫ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π —Å –Ω–∏–∑–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)
        
        shifts = self.db.query(Shift).filter(
            and_(
                Shift.start_time >= start_date,
                Shift.efficiency_score.isnot(None)
            )
        ).all()
        
        executor_performance = {}
        for shift in shifts:
            if shift.executor_id:
                if shift.executor_id not in executor_performance:
                    executor_performance[shift.executor_id] = []
                executor_performance[shift.executor_id].append(shift.efficiency_score)
        
        low_performers = []
        for executor_id, scores in executor_performance.items():
            avg_score = sum(scores) / len(scores)
            if avg_score < 65 and len(scores) >= 3:  # –ú–∏–Ω–∏–º—É–º 3 —Å–º–µ–Ω—ã –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                low_performers.append((executor_id, avg_score))
        
        if low_performers:
            recommendations.append(Recommendation(
                id="perf_001",
                type=RecommendationType.PERFORMANCE_IMPROVEMENT,
                priority=RecommendationPriority.HIGH,
                title="–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π —Å –Ω–∏–∑–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é",
                description=f"–í—ã—è–≤–ª–µ–Ω–æ {len(low_performers)} –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –Ω–∏–∂–µ 65%",
                impact="–ü–æ–≤—ã—à–µ–Ω–∏–µ –æ–±—â–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–º–∞–Ω–¥—ã –Ω–∞ 10-20%",
                effort="–°—Ä–µ–¥–Ω—è—è",
                timeline="2-4 –Ω–µ–¥–µ–ª–∏",
                actions=[
                    "–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —Å –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º–∏",
                    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –º–µ–Ω—Ç–æ—Ä—Å—Ç–≤–æ",
                    "–ê–Ω–∞–ª–∏–∑ –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–π –≤ —Ä–∞–±–æ—Ç–µ",
                    "–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤"
                ],
                metrics={"low_performers": len(low_performers)},
                confidence=80.0
            ))
        
        return recommendations
    
    async def _analyze_capacity_planning(self, period_days: int) -> List[Recommendation]:
        """–ê–Ω–∞–ª–∏–∑ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ—â–Ω–æ—Å—Ç–∏"""
        recommendations = []
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∑–∞–≥—Ä—É–∑–∫–∏
        daily_loads = await self._get_daily_load_trend(period_days)
        if daily_loads:
            trend = self._calculate_trend(daily_loads)
            
            if trend > 0.1:  # –†–∞—Å—Ç—É—â–∏–π —Ç—Ä–µ–Ω–¥
                recommendations.append(Recommendation(
                    id="capacity_001",
                    type=RecommendationType.CAPACITY_PLANNING,
                    priority=RecommendationPriority.MEDIUM,
                    title="–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —É–≤–µ–ª–∏—á–µ–Ω–∏—è –º–æ—â–Ω–æ—Å—Ç–∏",
                    description=f"–í—ã—è–≤–ª–µ–Ω —Ä–∞—Å—Ç—É—â–∏–π —Ç—Ä–µ–Ω–¥ –Ω–∞–≥—Ä—É–∑–∫–∏: +{trend*100:.1f}% –≤ –¥–µ–Ω—å",
                    impact="–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ —Å–∏—Å—Ç–µ–º—ã",
                    effort="–í—ã—Å–æ–∫–∞—è",
                    timeline="1-2 –º–µ—Å—è—Ü–∞",
                    actions=[
                        "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞–π–º–∞ –Ω–æ–≤—ã—Ö –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π",
                        "–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–º–µ–Ω",
                        "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏"
                    ],
                    metrics={"daily_trend": round(trend * 100, 2)},
                    confidence=75.0
                ))
        
        return recommendations
    
    async def _analyze_quality_enhancement(self, period_days: int) -> List[Recommendation]:
        """–ê–Ω–∞–ª–∏–∑ —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞"""
        recommendations = []
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –∫–∞—á–µ—Å—Ç–≤–∞
        quality_ratings = self.db.query(Shift.quality_rating).filter(
            and_(
                Shift.start_time >= start_date,
                Shift.quality_rating.isnot(None)
            )
        ).all()
        
        if quality_ratings:
            ratings = [r[0] for r in quality_ratings]
            avg_quality = sum(ratings) / len(ratings)
            
            if avg_quality < 4.0:  # –ù–∏–∂–µ "—Ö–æ—Ä–æ—à–æ"
                recommendations.append(Recommendation(
                    id="quality_001",
                    type=RecommendationType.QUALITY_ENHANCEMENT,
                    priority=RecommendationPriority.HIGH,
                    title="–ü–æ–≤—ã—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç",
                    description=f"–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞: {avg_quality:.1f}/5.0",
                    impact="–ü–æ–≤—ã—à–µ–Ω–∏–µ —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤ –∏ —Ä–µ–ø—É—Ç–∞—Ü–∏–∏",
                    effort="–°—Ä–µ–¥–Ω—è—è",
                    timeline="1-3 –º–µ—Å—è—Ü–∞",
                    actions=[
                        "–í–Ω–µ–¥—Ä–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –∫–æ–Ω—Ç—Ä–æ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞",
                        "–û–±—É—á–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞–±–æ—Ç",
                        "–†–µ–≥—É–ª—è—Ä–Ω—ã–µ –∞—É–¥–∏—Ç—ã –∏ –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å",
                        "–ú–æ—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –¥–ª—è –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π"
                    ],
                    metrics={"avg_quality": round(avg_quality, 2)},
                    confidence=85.0
                ))
        
        return recommendations
    
    async def _identify_bottlenecks(self, period_days: int) -> List[Recommendation]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É–∑–∫–∏—Ö –º–µ—Å—Ç"""
        recommendations = []
        
        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫–ª–∏–∫–∞
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)
        
        slow_shifts = self.db.query(Shift).filter(
            and_(
                Shift.start_time >= start_date,
                Shift.average_response_time > 180  # –ë–æ–ª—å—à–µ 3 —á–∞—Å–æ–≤
            )
        ).count()
        
        total_shifts = self.db.query(Shift).filter(
            Shift.start_time >= start_date
        ).count()
        
        if total_shifts > 0 and (slow_shifts / total_shifts) > 0.3:  # –ë–æ–ª–µ–µ 30% –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–º–µ–Ω
            recommendations.append(Recommendation(
                id="bottleneck_001",
                type=RecommendationType.BOTTLENECK_RESOLUTION,
                priority=RecommendationPriority.CRITICAL,
                title="–£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —É–∑–∫–∏—Ö –º–µ—Å—Ç –≤–æ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫–ª–∏–∫–∞",
                description=f"{(slow_shifts/total_shifts)*100:.1f}% —Å–º–µ–Ω –∏–º–µ—é—Ç –º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞",
                impact="–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è",
                effort="–°—Ä–µ–¥–Ω—è—è",
                timeline="2-3 –Ω–µ–¥–µ–ª–∏",
                actions=[
                    "–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–∞ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –∑–∞—è–≤–æ–∫",
                    "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏",
                    "–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤",
                    "–û–±—É—á–µ–Ω–∏–µ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–æ–≤"
                ],
                metrics={"slow_shifts_ratio": round((slow_shifts/total_shifts)*100, 1)},
                confidence=90.0
            ))
        
        return recommendations
    
    # =================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ ===================
    
    def _get_priority_weight(self, priority: RecommendationPriority) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å –≤–µ—Å–æ–≤–æ–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞"""
        weights = {
            RecommendationPriority.CRITICAL: 4,
            RecommendationPriority.HIGH: 3,
            RecommendationPriority.MEDIUM: 2,
            RecommendationPriority.LOW: 1
        }
        return weights.get(priority, 1)
    
    def _recommendation_to_dict(self, rec: Recommendation) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return {
            "id": rec.id,
            "type": rec.type.value,
            "priority": rec.priority.value,
            "title": rec.title,
            "description": rec.description,
            "impact": rec.impact,
            "effort": rec.effort,
            "timeline": rec.timeline,
            "actions": rec.actions,
            "metrics": rec.metrics,
            "confidence": rec.confidence
        }
    
    async def _analyze_time_coverage(self, shifts: List[Shift], target_date: date) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–∫—Ä—ã—Ç–∏—è (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
        covered_hours = set()
        for shift in shifts:
            if shift.start_time and shift.end_time:
                start_hour = shift.start_time.hour
                end_hour = shift.end_time.hour
                covered_hours.update(range(start_hour, end_hour + 1))
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ —á–∞—Å—ã (8-18)
        standard_hours = set(range(8, 19))
        gaps = standard_hours - covered_hours
        
        return {
            "covered_hours": sorted(list(covered_hours)),
            "gaps": [f"{h}:00-{h+1}:00" for h in sorted(gaps)],
            "coverage_percentage": (len(covered_hours) / 24) * 100
        }
    
    async def _get_historical_data_for_date(self, target_date: date) -> List[int]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–π –¥–∞—Ç—ã"""
        # –ù–∞–π—Ç–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ –¥–Ω–∏ –Ω–µ–¥–µ–ª–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–µ–¥–µ–ª—å
        weekday = target_date.weekday()
        historical_counts = []
        
        for weeks_back in range(1, 5):  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 4 –Ω–µ–¥–µ–ª–∏
            historical_date = target_date - timedelta(weeks=weeks_back)
            
            count = self.db.query(Request).filter(
                func.date(Request.created_at) == historical_date
            ).count()
            
            if count > 0:
                historical_counts.append(count)
        
        return historical_counts
    
    async def _predict_daily_load(self, target_date: date, historical_data: List[int]) -> int:
        """–ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–Ω–µ–≤–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏"""
        if not historical_data:
            return 10  # –î–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        
        # –ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–µ–¥–Ω–µ–µ —Å —Ç—Ä–µ–Ω–¥–æ–º
        avg_load = sum(historical_data) / len(historical_data)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –¥–µ–Ω—å –Ω–µ–¥–µ–ª–∏
        weekday_multipliers = {
            0: 1.2,  # –ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫
            1: 1.1,  # –í—Ç–æ—Ä–Ω–∏–∫
            2: 1.0,  # –°—Ä–µ–¥–∞
            3: 1.0,  # –ß–µ—Ç–≤–µ—Ä–≥
            4: 1.1,  # –ü—è—Ç–Ω–∏—Ü–∞
            5: 0.7,  # –°—É–±–±–æ—Ç–∞
            6: 0.5   # –í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
        }
        
        multiplier = weekday_multipliers.get(target_date.weekday(), 1.0)
        return int(avg_load * multiplier)
    
    def _generate_action_plan(self, recommendations: List[str]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ –¥–µ–π—Å—Ç–≤–∏–π"""
        if not recommendations:
            return ["–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–º–µ–Ω –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ"]
        
        actions = []
        if any("–ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–∞" in r for r in recommendations):
            actions.append("1. –ü–µ—Ä–µ—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É —Å –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å–º–µ–Ω")
        
        if any("–Ω–µ–¥–æ–≥—Ä—É–∂–µ–Ω–∞" in r for r in recommendations):
            actions.append("2. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–¥–æ–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–º–µ–Ω—ã")
        
        if any("–¥–æ–±–∞–≤–∏—Ç—å —Å–º–µ–Ω—ã" in r for r in recommendations):
            actions.append("3. –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–º–µ–Ω—ã")
        
        return actions
    
    async def _find_overloaded_executors(self, start_date: datetime, end_date: datetime) -> List[int]:
        """–ù–∞–π—Ç–∏ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π"""
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–º–µ–Ω—ã –ø–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º
        executor_loads = {}
        shifts = self.db.query(Shift).filter(
            and_(
                Shift.start_time >= start_date,
                Shift.executor_id.isnot(None)
            )
        ).all()
        
        for shift in shifts:
            executor_id = shift.executor_id
            if executor_id not in executor_loads:
                executor_loads[executor_id] = 0
            executor_loads[executor_id] += shift.current_request_count or 0
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö (–±–æ–ª—å—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –≤ 1.5 —Ä–∞–∑–∞)
        if not executor_loads:
            return []
        
        avg_load = sum(executor_loads.values()) / len(executor_loads)
        threshold = avg_load * 1.5
        
        return [executor_id for executor_id, load in executor_loads.items() if load > threshold]
    
    async def _analyze_specialization_efficiency(self, start_date: datetime, end_date: datetime) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è–º"""
        specialization_stats = {}
        
        for spec in SPECIALIZATIONS:
            # –ù–∞–π—Ç–∏ —Å–º–µ–Ω—ã —Å —ç—Ç–æ–π —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π
            shifts = self.db.query(Shift).filter(
                and_(
                    Shift.start_time >= start_date,
                    Shift.specialization_focus.contains([spec])
                )
            ).all()
            
            if shifts:
                avg_efficiency = sum(s.efficiency_score or 0 for s in shifts) / len(shifts)
                specialization_stats[spec] = avg_efficiency / 100  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0-1
        
        return specialization_stats
    
    def _prioritize_bottleneck_actions(self, bottlenecks: List[Dict]) -> List[str]:
        """–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –¥–µ–π—Å—Ç–≤–∏–π –ø–æ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é —É–∑–∫–∏—Ö –º–µ—Å—Ç"""
        actions = []
        
        for bottleneck in bottlenecks:
            if bottleneck["type"] == "slow_response":
                actions.append("üèÉ –°–†–û–ß–ù–û: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –Ω–∞ –∑–∞—è–≤–∫–∏")
            elif bottleneck["type"] == "pending_backlog":
                actions.append("üìä –í–ê–ñ–ù–û: –†–∞–∑–≥—Ä—É–∑–∏—Ç—å –æ—á–µ—Ä–µ–¥—å –æ–∂–∏–¥–∞—é—â–∏—Ö –∑–∞—è–≤–æ–∫")
            elif bottleneck["type"] == "executor_overload":
                actions.append("‚öñÔ∏è –°–†–ï–î–ù–ï: –ü–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π")
        
        return actions[:5]  # –¢–æ–ø-5 –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
    
    def _estimate_bottleneck_impact(self, bottlenecks: List[Dict]) -> Dict[str, str]:
        """–û—Ü–µ–Ω–∫–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è –æ—Ç —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —É–∑–∫–∏—Ö –º–µ—Å—Ç"""
        if not bottlenecks:
            return {"message": "–£–∑–∫–∏—Ö –º–µ—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"}
        
        impact_estimates = {
            "efficiency_improvement": "15-30%",
            "response_time_reduction": "20-40%",
            "customer_satisfaction": "10-20%",
            "cost_optimization": "5-15%"
        }
        
        return impact_estimates
    
    async def _get_daily_load_trend(self, period_days: int) -> List[int]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç—Ä–µ–Ω–¥ –¥–Ω–µ–≤–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–∏"""
        end_date = datetime.now().date()
        daily_loads = []
        
        for i in range(period_days):
            date_to_check = end_date - timedelta(days=i)
            daily_count = self.db.query(Request).filter(
                func.date(Request.created_at) == date_to_check
            ).count()
            daily_loads.append(daily_count)
        
        return list(reversed(daily_loads))  # –û—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º
    
    def _calculate_trend(self, values: List[int]) -> float:
        """–†–∞—Å—á–µ—Ç —Ç—Ä–µ–Ω–¥–∞ (–ø—Ä–æ—Å—Ç–∞—è –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è)"""
        if len(values) < 2:
            return 0.0
        
        n = len(values)
        x = list(range(n))
        
        # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞
        x_mean = sum(x) / n
        y_mean = sum(values) / n
        
        numerator = sum((x[i] - x_mean) * (values[i] - y_mean) for i in range(n))
        denominator = sum((x[i] - x_mean) ** 2 for i in range(n))
        
        if denominator == 0:
            return 0.0
        
        slope = numerator / denominator
        return slope / max(y_mean, 1)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ —Å—Ä–µ–¥–Ω–µ–º—É –∑–Ω–∞—á–µ–Ω–∏—é