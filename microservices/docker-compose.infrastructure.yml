# ðŸš€ UK Management Bot - Infrastructure Foundation
# Sprint 0: Core Infrastructure Services
# Version: 1.0.0
# Date: 2025-09-26

version: '3.9'

networks:
  uk_microservices:
    driver: bridge
    name: uk_microservices
    ipam:
      config:
        - subnet: 172.28.0.0/16

volumes:
  postgres_auth_data:
  postgres_users_data:
  postgres_requests_data:
  postgres_assignments_data:
  postgres_shifts_data:
  postgres_notifications_data:
  postgres_analytics_data:
  postgres_integration_data:
  redis_data:
  vault_data:
  prometheus_data:
  grafana_data:
  media_storage:

services:
  # ==========================================
  # REVERSE PROXY & API GATEWAY
  # ==========================================
  traefik:
    image: traefik:v3.0
    container_name: uk_traefik
    restart: always
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"  # Traefik dashboard
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./traefik/traefik.yml:/etc/traefik/traefik.yml:ro
      - ./traefik/dynamic:/etc/traefik/dynamic:ro
      - ./traefik/certs:/certs
    networks:
      - uk_microservices
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.traefik.rule=Host(`traefik.uk.local`)"
      - "traefik.http.services.traefik.loadbalancer.server.port=8080"
    environment:
      - TRAEFIK_LOG_LEVEL=INFO
      - TRAEFIK_ACCESSLOG=true

  # ==========================================
  # DATABASES
  # ==========================================

  # Auth Service Database
  postgres_auth:
    image: postgres:15-alpine
    container_name: uk_postgres_auth
    restart: always
    environment:
      POSTGRES_DB: uk_auth_db
      POSTGRES_USER: uk_auth_user
      POSTGRES_PASSWORD: ${AUTH_DB_PASSWORD:-auth_secret_pass}
    volumes:
      - postgres_auth_data:/var/lib/postgresql/data
      - ./init-scripts/auth:/docker-entrypoint-initdb.d
    networks:
      uk_microservices:
        ipv4_address: 172.28.1.1
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U uk_auth_user -d uk_auth_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Users Service Database
  postgres_users:
    image: postgres:15-alpine
    container_name: uk_postgres_users
    restart: always
    environment:
      POSTGRES_DB: uk_users_db
      POSTGRES_USER: uk_users_user
      POSTGRES_PASSWORD: ${USERS_DB_PASSWORD:-users_secret_pass}
    volumes:
      - postgres_users_data:/var/lib/postgresql/data
      - ./init-scripts/users:/docker-entrypoint-initdb.d
    networks:
      uk_microservices:
        ipv4_address: 172.28.1.2
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U uk_users_user -d uk_users_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Requests Service Database
  postgres_requests:
    image: postgres:15-alpine
    container_name: uk_postgres_requests
    restart: always
    environment:
      POSTGRES_DB: uk_requests_db
      POSTGRES_USER: uk_requests_user
      POSTGRES_PASSWORD: ${REQUESTS_DB_PASSWORD:-requests_secret_pass}
    volumes:
      - postgres_requests_data:/var/lib/postgresql/data
      - ./init-scripts/requests:/docker-entrypoint-initdb.d
    networks:
      uk_microservices:
        ipv4_address: 172.28.1.3
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U uk_requests_user -d uk_requests_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Assignments Service Database
  postgres_assignments:
    image: postgres:15-alpine
    container_name: uk_postgres_assignments
    restart: always
    environment:
      POSTGRES_DB: uk_assignments_db
      POSTGRES_USER: uk_assignments_user
      POSTGRES_PASSWORD: ${ASSIGNMENTS_DB_PASSWORD:-assignments_secret_pass}
    volumes:
      - postgres_assignments_data:/var/lib/postgresql/data
      - ./init-scripts/assignments:/docker-entrypoint-initdb.d
    networks:
      uk_microservices:
        ipv4_address: 172.28.1.4
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U uk_assignments_user -d uk_assignments_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Shifts Service Database
  postgres_shifts:
    image: postgres:15-alpine
    container_name: uk_postgres_shifts
    restart: always
    environment:
      POSTGRES_DB: uk_shifts_db
      POSTGRES_USER: uk_shifts_user
      POSTGRES_PASSWORD: ${SHIFTS_DB_PASSWORD:-shifts_secret_pass}
    volumes:
      - postgres_shifts_data:/var/lib/postgresql/data
      - ./init-scripts/shifts:/docker-entrypoint-initdb.d
    networks:
      uk_microservices:
        ipv4_address: 172.28.1.5
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U uk_shifts_user -d uk_shifts_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Notifications Service Database
  postgres_notifications:
    image: postgres:15-alpine
    container_name: uk_postgres_notifications
    restart: always
    environment:
      POSTGRES_DB: uk_notifications_db
      POSTGRES_USER: uk_notifications_user
      POSTGRES_PASSWORD: ${NOTIFICATIONS_DB_PASSWORD:-notifications_secret_pass}
    volumes:
      - postgres_notifications_data:/var/lib/postgresql/data
      - ./init-scripts/notifications:/docker-entrypoint-initdb.d
    networks:
      uk_microservices:
        ipv4_address: 172.28.1.6
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U uk_notifications_user -d uk_notifications_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Analytics Service Database
  postgres_analytics:
    image: postgres:15-alpine
    container_name: uk_postgres_analytics
    restart: always
    environment:
      POSTGRES_DB: uk_analytics_db
      POSTGRES_USER: uk_analytics_user
      POSTGRES_PASSWORD: ${ANALYTICS_DB_PASSWORD:-analytics_secret_pass}
    volumes:
      - postgres_analytics_data:/var/lib/postgresql/data
      - ./init-scripts/analytics:/docker-entrypoint-initdb.d
    networks:
      uk_microservices:
        ipv4_address: 172.28.1.7
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U uk_analytics_user -d uk_analytics_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Integration Hub Database
  postgres_integration:
    image: postgres:15-alpine
    container_name: uk_postgres_integration
    restart: always
    environment:
      POSTGRES_DB: uk_integration_db
      POSTGRES_USER: uk_integration_user
      POSTGRES_PASSWORD: ${INTEGRATION_DB_PASSWORD:-integration_secret_pass}
    volumes:
      - postgres_integration_data:/var/lib/postgresql/data
      - ./init-scripts/integration:/docker-entrypoint-initdb.d
    networks:
      uk_microservices:
        ipv4_address: 172.28.1.8
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U uk_integration_user -d uk_integration_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==========================================
  # CACHE & MESSAGE BUS
  # ==========================================
  redis:
    image: redis:7-alpine
    container_name: uk_redis
    restart: always
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    networks:
      uk_microservices:
        ipv4_address: 172.28.2.1
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==========================================
  # SECRETS MANAGEMENT
  # ==========================================
  vault:
    image: hashicorp/vault:latest
    container_name: uk_vault
    restart: always
    cap_add:
      - IPC_LOCK
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_ROOT_TOKEN:-myroot}
      VAULT_DEV_LISTEN_ADDRESS: "0.0.0.0:8200"
    ports:
      - "8200:8200"
    volumes:
      - vault_data:/vault/data
      - ./vault/config:/vault/config
    networks:
      uk_microservices:
        ipv4_address: 172.28.3.1
    healthcheck:
      test: ["CMD", "vault", "status"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==========================================
  # MONITORING & OBSERVABILITY
  # ==========================================

  # Prometheus for metrics
  prometheus:
    image: prom/prometheus:latest
    container_name: uk_prometheus
    restart: always
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    ports:
      - "9090:9090"
    volumes:
      - prometheus_data:/prometheus
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/alerts:/etc/prometheus/alerts
    networks:
      uk_microservices:
        ipv4_address: 172.28.4.1
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana for dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: uk_grafana
    restart: always
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_INSTALL_PLUGINS: grafana-clock-panel,redis-app
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      uk_microservices:
        ipv4_address: 172.28.4.2
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: uk_jaeger
    restart: always
    environment:
      COLLECTOR_ZIPKIN_HOST_PORT: 9411
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"  # Jaeger UI
      - "14250:14250"
      - "14268:14268"
      - "9411:9411"
    networks:
      uk_microservices:
        ipv4_address: 172.28.4.3
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:16686/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: uk_otel_collector
    restart: always
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel/otel-collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "8888:8888"   # Prometheus metrics exposed by the collector
      - "8889:8889"   # Prometheus exporter metrics
    networks:
      uk_microservices:
        ipv4_address: 172.28.4.4
    depends_on:
      - jaeger
      - prometheus

  # ==========================================
  # LOGGING
  # ==========================================

  # Elasticsearch for log storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
    container_name: uk_elasticsearch
    restart: always
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - ./elasticsearch/data:/usr/share/elasticsearch/data
    networks:
      uk_microservices:
        ipv4_address: 172.28.5.1
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Kibana for log visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.10.2
    container_name: uk_kibana
    restart: always
    environment:
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
    ports:
      - "5601:5601"
    networks:
      uk_microservices:
        ipv4_address: 172.28.5.2
    depends_on:
      - elasticsearch
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5601/api/status"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Logstash for log processing
  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.2
    container_name: uk_logstash
    restart: always
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
    ports:
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xms256m -Xmx256m"
    networks:
      uk_microservices:
        ipv4_address: 172.28.5.3
    depends_on:
      - elasticsearch